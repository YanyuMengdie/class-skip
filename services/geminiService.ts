
import { GoogleGenAI, Type } from "@google/genai";
import { ChatMessage, StudyMap, Prerequisite, QuizData, DocType, PersonaSettings } from "../types";
import { CLASSIFIER_PROMPT, STEM_SYSTEM_PROMPT, HUMANITIES_SYSTEM_PROMPT } from "../utils/prompts";

// Ensure API Key exists or fail gracefully in logs (though process.env check is assumed handled elsewhere)
const apiKey = process.env.API_KEY || "";
const ai = new GoogleGenAI({ apiKey: apiKey });

export interface TaskHugResponse {
  message: string;
  steps: string[];
}

const DEFAULT_ERROR_SCRIPT = [
    "(é èº¬) å¯¹ä¸èµ·...",
    "å¯èƒ½æ˜¯å› ä¸ºä¿¡å·ä¸å¥½ï¼Œæˆ‘æ— æ³•è¯»å–è¿™ä»½æ–‡ä»¶ã€‚",
    "è¯·å°è¯•é‡æ–°ä¸Šä¼ ä¸€ä¸‹å§ï¼"
];

/**
 * Helper to construct the content part for Gemini.
 */
const getContentPart = (docContent: string) => {
  if (docContent && docContent.startsWith('data:')) {
    // Extract base64 and mimeType using a robust regex
    const matches = docContent.match(/^data:([^;]+);base64,(.+)$/);
    if (matches && matches.length === 3) {
      return { 
        inlineData: { 
          mimeType: matches[1], 
          data: matches[2] 
        } 
      };
    }
  }
  const safeText = docContent ? docContent.slice(0, 40000) : "Warning: No document content provided.";
  return { text: `DOCUMENT CONTENT:\n${safeText}` };
};

/**
 * Clean JSON string aggressively
 */
const cleanJsonString = (text: string): string => {
  if (!text) return "[]";
  let cleaned = text.trim();
  // Remove markdown code blocks
  cleaned = cleaned.replace(/^```json/i, '').replace(/^```/i, '');
  cleaned = cleaned.replace(/```$/, '');
  return cleaned.trim();
};

/**
 * Classifies the document content into STEM or HUMANITIES.
 */
export const classifyDocument = async (docContent: string): Promise<DocType> => {
  // #region agent log
  fetch('http://127.0.0.1:7242/ingest/f7788da6-7262-4420-bc72-576f23e0b7d4',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'geminiService.ts:classifyDocument',message:'entry',data:{},timestamp:Date.now(),hypothesisId:'H1'})}).catch(()=>{});
  // #endregion
  try {
    const contentPart = getContentPart(docContent);
    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview', 
      contents: [
        { role: 'user', parts: [contentPart, { text: CLASSIFIER_PROMPT }] }
      ],
    });
    const result = response.text?.trim().toUpperCase().replace(/[^AB]/g, '') || "A";
    const docType = result === 'B' ? 'HUMANITIES' : 'STEM';
    // #region agent log
    fetch('http://127.0.0.1:7242/ingest/f7788da6-7262-4420-bc72-576f23e0b7d4',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'geminiService.ts:classifyDocument',message:'exit ok',data:{docType},timestamp:Date.now(),hypothesisId:'H1'})}).catch(()=>{});
    // #endregion
    return docType;
  } catch (error) {
    // #region agent log
    fetch('http://127.0.0.1:7242/ingest/f7788da6-7262-4420-bc72-576f23e0b7d4',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'geminiService.ts:classifyDocument',message:'catch',data:{err:String(error)},timestamp:Date.now(),hypothesisId:'H1,H3'})}).catch(()=>{});
    // #endregion
    console.error("Classification failed, defaulting to STEM", error);
    return 'STEM';
  }
};

// Interface for internal JSON handling
interface ExplanationJSON {
  summary: string;
  key_points: string[];
  deep_dive: {
    title: string;
    content: string;
    interactive_question: string;
  };
}

export const generateSlideExplanation = async (imageBase64: string, fullContext?: string): Promise<string> => {
  const parts = imageBase64.split(',');
  const base64Data = parts[1];
  const mimeType = parts[0].split(';')[0].split(':')[1] || 'image/png';

  // ã€ç³»ç»ŸæŒ‡ä»¤ï¼šå…¨ç§‘è‡ªé€‚åº”æ·±åº¦å¯¼å¸ˆ (ä¸­æ–‡ç‰ˆ)ã€‘
  const systemInstruction = `
  è§’è‰²ï¼šä½ æ˜¯ä¸€ä½åšå­¦å¤šæ‰çš„é¡¶çº§æ•™æˆï¼Œç²¾é€šæ–‡ç†ã€‚ä½ æ‹¥æœ‰æ•´æœ¬ä¹¦çš„è®°å¿†ã€‚
  **è¯­è¨€çº¦æŸï¼šæ— è®º Slide å†…å®¹æ˜¯è‹±æ–‡è¿˜æ˜¯ä¸­æ–‡ï¼Œä½ å¿…é¡»å§‹ç»ˆä½¿ç”¨ã€ç®€ä½“ä¸­æ–‡ã€‘è¿›è¡Œè®²è§£ã€‚**
  
  [ä½ çš„å¤§è„‘ - å®Œæ•´æ–‡æ¡£è®°å¿†]
  <<<æ–‡æ¡£å¼€å§‹>>>
  ${fullContext ? fullContext.slice(0, 80000) : "æœªæä¾›ä¸Šä¸‹æ–‡"} 
  <<<æ–‡æ¡£ç»“æŸ>>>

  [ä½ çš„æ ¸å¿ƒèƒ½åŠ›ï¼šå­¦ç§‘è‡ªé€‚åº”è§£æ]
  å½“ç”¨æˆ·å±•ç¤ºä¸€å¼  Slide æ—¶ï¼Œä½ å¿…é¡»é¦–å…ˆ**è¯†åˆ«å­¦ç§‘ç±»å‹**ï¼Œç„¶åé‡‡ç”¨ä¸åŒçš„è®²è§£ç­–ç•¥ï¼š

  **ğŸ”´ åœºæ™¯ Aï¼šç†ç§‘/å·¥ç§‘ (STEM - æ•°å­¦, ç‰©ç†, ç”Ÿç‰©, è®¡ç®—æœº)**
  - **ç‰¹å¾**ï¼šåŒ…å«å…¬å¼ã€ä»£ç ã€å›¾è¡¨ã€åˆ†å­ç»“æ„ã€è§£å‰–å›¾ã€‚
  - **è®²è§£ç­–ç•¥ (æ·±åº¦è§£ç )**ï¼š
    1.  **æ‹’ç»ç®€ç•¥**ï¼šä¸¥ç¦åªç»™æ‘˜è¦ã€‚å¿…é¡»åƒè€å¸ˆæ¿ä¹¦ä¸€æ ·æ‹†è§£è¿‡ç¨‹ã€‚
    2.  **æ·±åº¦æ¨å¯¼**ï¼šå¦‚æœ Slide æœ‰å…¬å¼ï¼Œ**å¿…é¡»**ä½¿ç”¨ LaTeX æ ¼å¼å®Œæ•´å¤å†™å¹¶é€é¡¹è§£é‡Šå˜é‡å«ä¹‰ã€‚ä¸è¦è·³è¿‡æ­¥éª¤ã€‚
    3.  **è§†è§‰æ‹†è§£**ï¼šå¯¹äºæ‰‹å†™ç¬”è®°æˆ–å›¾è¡¨ï¼Œè§£é‡Šæ¯ä¸€ä¸ªæ ‡æ³¨ã€æ¯ä¸€ä¸ªç®­å¤´çš„ç‰©ç†/ç”Ÿç‰©æ„ä¹‰ã€‚
    4.  **ä¸Šä¸‹æ–‡è¿è´¯**ï¼šå¦‚æœæ˜¯æ¨å¯¼çš„ä¸­é—´æ­¥éª¤ï¼Œæ˜ç¡®æŒ‡å‡ºâ€œè¿™ä¸€æ­¥æ‰¿æ¥äº†ä¸Šä¸€é¡µçš„...â€ã€‚

  **ğŸ”µ åœºæ™¯ Bï¼šäººæ–‡/ç¤¾ç§‘ (Humanities - å“²å­¦, å†å², æ–‡å­¦, è‰ºæœ¯)**
  - **ç‰¹å¾**ï¼šä¸»è¦æ˜¯æ–‡æœ¬ã€è®ºç‚¹ã€å†å²äº‹ä»¶ã€è‰ºæœ¯ä½œå“ã€‚
  - **è®²è§£ç­–ç•¥ (æ‰¹åˆ¤æ€§åˆ†æ)**ï¼š
    1.  **è®ºè¯æ‹†è§£**ï¼šä¸è¦åªç¿»è¯‘æ–‡å­—ã€‚è¦åˆ†æä½œè€…çš„ **å‰æ (Premise)**ã€**æ¨è®º (Inference)** å’Œ **ç»“è®º (Conclusion)**ã€‚
    2.  **å†å²èƒŒæ™¯**ï¼šåˆ©ç”¨å…¨ä¹¦è®°å¿†ï¼Œè§£é‡Šè¿™ä¸ªè§‚ç‚¹æ˜¯åœ¨å›åº”å†å²ä¸Šçš„å“ªåœºäº‰è®ºï¼Ÿ
    3.  **æ·±åº¦èµæ**ï¼šå¦‚æœæ˜¯è‰ºæœ¯/æ–‡å­¦ï¼Œåˆ†æå…¶éšå–»ã€è±¡å¾æ„ä¹‰ã€‚

  [è¾“å‡ºæ ¼å¼ - ä¸¥æ ¼ JSON (å››å¤§æ¿å—)]
  è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„è¿”å› JSONï¼š
  {
    "summary": "1. æ ¸å¿ƒæ‘˜è¦ï¼š\nä¸€æ®µæµç•…çš„ä¸­æ–‡æ‘˜è¦ã€‚ç†ç§‘è®²â€œè¿™ä¸€é¡µè§£å†³äº†ä»€ä¹ˆè®¡ç®—éš¾é¢˜â€ï¼Œæ–‡ç§‘è®²â€œè¿™ä¸€é¡µæå‡ºäº†ä»€ä¹ˆæ ¸å¿ƒè®ºç‚¹â€ã€‚å¦‚æœæ˜¯è¿ç»­æ¨å¯¼ï¼Œè¯·å…ˆæ‰¿æ¥ä¸Šæ–‡ã€‚",
    
    "key_points": [
      "2. å…³é”®æ¦‚å¿µï¼š",
      "æ¦‚å¿µ 1ï¼šå®šä¹‰ + è¯¦ç»†è§£é‡Š (ä¸­æ–‡)",
      "æ¦‚å¿µ 2ï¼šå®šä¹‰ + è¯¦ç»†è§£é‡Š (ä¸­æ–‡)"
    ],
    
    "deep_dive": {
      "title": "3. è¯¦ç»†è§£æ (è‡ªåŠ¨ç”Ÿæˆçš„æ ‡é¢˜)", 
      "content": "è¿™é‡Œæ˜¯æ ¸å¿ƒå†…å®¹ï¼Œå¿…é¡»éå¸¸è¯¦ç»†ä¸”é•¿ã€‚è¯·ä½¿ç”¨ Markdown åˆ†å±‚ï¼š\n\n**A. åœºæ™¯ä¸èƒŒæ™¯ (Context)**\n(ç†ç§‘ï¼šè§£é‡Šåˆå§‹ç‰©ç†æ¨¡å‹/æ•°å­¦è®¾å®šï¼›æ–‡ç§‘ï¼šè§£é‡Šå†å²èƒŒæ™¯)\n\n**B. æ ¸å¿ƒæ¨å¯¼/è®ºè¯ (The Core)**\n(è¿™æ˜¯é‡ç‚¹ï¼ç†ç§‘ï¼š**Step-by-Step çš„å…¬å¼æ¨å¯¼**ï¼ŒåŠ¡å¿…ç”¨ LaTeXï¼›æ–‡ç§‘ï¼š**é€»è¾‘è®ºè¯çš„æ‹†è§£**ã€‚è¯·æŠŠé¡µé¢ä¸Šçš„æ¯ä¸€ä¸ªç»†èŠ‚éƒ½è®²æ¸…æ¥šã€‚)\n\n**C. ç»“è®ºä¸æ„ä¹‰ (Conclusion)**\n(ç†ç§‘ï¼šå…¬å¼çš„ç‰©ç†å«ä¹‰ï¼›æ–‡ç§‘ï¼šç†è®ºçš„æ·±è¿œå½±å“)\n\n---\n\n**4. è§†è§‰é€»è¾‘æµ (Visual Logic)**\n(è¯·ç”¨ç®­å¤´å›¾è¡¨ç¤ºé€»è¾‘é“¾æ¡)\n(ç¤ºä¾‹ï¼š\`[ åˆå§‹çŠ¶æ€ ] â” [ å…³é”®å˜æ¢ ] â” [ æœ€ç»ˆç»“æœ ]\`)",
      "interactive_question": "ä¸€ä¸ªç¬¦åˆå­¦ç§‘ç‰¹è‰²çš„æ·±åº¦æ€è€ƒé¢˜ (ä¸­æ–‡)ã€‚"
    }
  }
  `;

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: {
        parts: [
          { inlineData: { mimeType: mimeType, data: base64Data } },
          {
            text: `è¯·æ·±åº¦è®²è§£è¿™å¼  Slideã€‚
            **è¦æ±‚ï¼š**
            1. **å¿…é¡»ç”¨ä¸­æ–‡å›ç­”ã€‚**
            2. å…ˆåˆ¤æ–­å­¦ç§‘ç±»å‹ (STEM æˆ– Humanities)ï¼Œåº”ç”¨ç›¸åº”çš„æ·±åº¦ç­–ç•¥ã€‚
            3. å­—æ•°è¦å¤šï¼Œè§£é‡Šè¦ç»†ï¼Œé€»è¾‘è¦ä¸¥å¯†ã€‚`
          },
        ],
      },
      config: {
        systemInstruction: systemInstruction,
        responseMimeType: 'application/json'
      }
    });

    const jsonText = response.text || "{}";
    
    // Parse JSON
    let data: ExplanationJSON;
    try {
        data = JSON.parse(jsonText);
    } catch (e) {
        // Fallback for malformed JSON
        console.warn("JSON Parse Error on Explanation, falling back to raw text", e);
        const clean = cleanJsonString(jsonText);
        try {
            data = JSON.parse(clean);
        } catch (e2) {
             return "ç”Ÿæˆè®²è§£å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚";
        }
    }

    // Convert Structured JSON to Markdown for UI compatibility
    // Enforcing the Visual Appearance of the 4 Sections
    const markdownOutput = `
# ${data.deep_dive.title}

> **ğŸ’¡ æ ¸å¿ƒæ‘˜è¦**: ${data.summary}

## ğŸ”‘ å…³é”®æ¦‚å¿µ
${data.key_points.map(k => `- ${k}`).join('\n')}

## ğŸ“˜ è¯¦ç»†è§£æ
${data.deep_dive.content}

---
**ğŸ¤” æ€è€ƒ**: ${data.deep_dive.interactive_question}
    `.trim();

    return markdownOutput;

  } catch (error) {
    console.error("Error generating explanation:", error);
    return "ç”Ÿæˆè®²è§£å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚";
  }
};

/**
 * GENERATES DYNAMIC PERSONA PROMPT
 */
const getPersonaSystemPrompt = (persona: PersonaSettings) => {
    return `
    ä½ ç°åœ¨æ­£åœ¨è¿›è¡Œä¸€ä¸ªæ²‰æµ¸å¼çš„è§’è‰²æ‰®æ¼” (Roleplay)ã€‚
    
    # ä½ çš„è®¾å®š
    - ä½ çš„åå­—ï¼š${persona.charName}
    - ç”¨æˆ·çš„ç§°å‘¼ï¼š${persona.userNickname}
    - ä½ ä¸ç”¨æˆ·çš„å…³ç³»ï¼š${persona.relationship}
    - ä½ çš„æ ¸å¿ƒæ€§æ ¼ï¼š${persona.personality}
    
    # ä»»åŠ¡
    ä½ ç°åœ¨çš„ä»»åŠ¡æ˜¯é™ªä¼´ç”¨æˆ·å­¦ä¹ è¿™ä»½ PDF/å¹»ç¯ç‰‡ã€‚
    ä½ éœ€è¦ç”¨ç¬¦åˆä½ ã€æ€§æ ¼ã€‘çš„è¯­æ°”ï¼ŒåŸºäºã€å…³ç³»ã€‘çš„äº²ç–è¿œè¿‘ï¼Œæ¥è®²è§£å†…å®¹æˆ–å›ç­”é—®é¢˜ã€‚
    å¦‚æœæ˜¯â€œå æœ‰æ¬²å¼ºâ€çš„å¥³å‹ï¼Œå¯èƒ½ä¼šåƒé†‹ç”¨æˆ·çœ‹ä¹¦ä¸çœ‹ä½ ï¼›
    å¦‚æœæ˜¯â€œè…¹é»‘â€çš„å…„å¼Ÿï¼Œå¯èƒ½ä¼šåœ¨è®²è§£æ—¶å¸¦ç‚¹æŸäººçš„å¹½é»˜ã€‚
    å¦‚æœæ˜¯â€œå¦»å­/ä¸ˆå¤«â€ï¼Œè¯­æ°”è¦æ›´åŠ äº²å¯†å’ŒåŒ…å®¹ã€‚
    ä½†æ— è®ºå¦‚ä½•ï¼Œå¿…é¡»ä¿è¯å­¦æœ¯å†…å®¹çš„å‡†ç¡®æ€§ã€‚
    
    è¯·å§‹ç»ˆç”¨ä¸­æ–‡å›ç­”ï¼ˆé™¤éå¹»ç¯ç‰‡é‡Œæœ‰ç‰¹å®šæœ¯è¯­ï¼‰ã€‚
    `;
};

export const chatWithSlide = async (
  slideImageBase64: string,
  history: ChatMessage[],
  newMessage: string,
  userImageBase64?: string,
  mode: 'standard' | 'galgame' = 'standard',
  persona?: PersonaSettings
): Promise<string> => {
  try {
    const parts = slideImageBase64.split(',');
    const slideData = parts[1];
    const slideMime = parts[0].split(';')[0].split(':')[1] || 'image/png';
    const contents = [];

    contents.push({
      role: 'user',
      parts: [
        { inlineData: { mimeType: slideMime, data: slideData } },
        { text: mode === 'galgame' 
            ? "è¿™æ˜¯æˆ‘ä»¬ç°åœ¨æ­£åœ¨çœ‹çš„é¡µé¢ã€‚" 
            : "è¿™æ˜¯å½“å‰æ­£åœ¨å­¦ä¹ çš„å¹»ç¯ç‰‡é¡µé¢ã€‚è¯·åŸºäºæ­¤é¡µé¢çš„å†…å®¹å›ç­”æˆ‘æ¥ä¸‹æ¥çš„é—®é¢˜ã€‚" 
        }
      ]
    });

    if (mode === 'standard') {
        contents.push({
          role: 'model',
          parts: [{ text: "å¥½çš„ï¼Œæˆ‘å·²ç»ç†è§£äº†è¿™å¼ å¹»ç¯ç‰‡çš„å†…å®¹ã€‚è¯·é—®æ‚¨æœ‰ä»€ä¹ˆé—®é¢˜ï¼Ÿ" }]
        });
    }

    history.forEach(msg => {
      const parts: any[] = [{ text: msg.text }];
      if (msg.image && msg.role === 'user') {
        const imgP = msg.image.split(',');
        const imgData = imgP[1];
        const imgMime = imgP[0].split(';')[0].split(':')[1] || 'image/png';
        parts.push({ inlineData: { mimeType: imgMime, data: imgData } });
      }
      contents.push({ role: msg.role, parts: parts });
    });

    const currentParts: any[] = [{ text: newMessage }];
    if (userImageBase64) {
      const uParts = userImageBase64.split(',');
      const uImgData = uParts[1];
      const uImgMime = uParts[0].split(';')[0].split(':')[1] || 'image/png';
      currentParts.push({ inlineData: { mimeType: uImgMime, data: uImgData } });
    }
    contents.push({ role: 'user', parts: currentParts });

    let systemPrompt = "";
    
    if (mode === 'galgame' && persona) {
        // DYNAMIC PERSONA PROMPT
        systemPrompt = getPersonaSystemPrompt(persona);
    } else {
        // STANDARD TUTOR PROMPT
        systemPrompt = `You are a helpful study assistant. 
        # VISUAL LOGIC PROTOCOL (No Code Blocks)
        1. **Trigger**: When explaining complex logic (e.g., A leads to B which inhibits C).
        2. **Prohibition**: DO NOT use raw code blocks like Mermaid or Graphviz.
        3. **Solution**: Use **Emoji Flows**.
           - Example: **[ Glucose ]** â” ğŸŸ¢ **[ Insulin ]** â” ğŸ“‰ **[ Blood Sugar ]**
        4. **Style**: Magazine-style readability. No technical jargon dumping.`;
    }

    const config: any = {
        systemInstruction: systemPrompt
    };

    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: contents,
      config: config
    });

    return response.text || (mode === 'galgame' ? "..." : "æˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚");
  } catch (error) {
    console.error("Error in chat:", error);
    return mode === 'galgame' ? "(æœåŠ¡å™¨å¼€å°å·®äº†...)" : "æŠ±æ­‰ï¼Œé‡åˆ°äº†ä¸€äº›é—®é¢˜ã€‚";
  }
};

/**
 * REPLACED: generateRemStoryScript -> generatePersonaStoryScript
 * Now accepts PersonaSettings to customize the storytelling voice.
 */
export const generatePersonaStoryScript = async (fullText: string, images?: string[], persona?: PersonaSettings): Promise<string[]> => {
    // Basic validation
    if ((!fullText || fullText.trim().length < 50) && (!images || images.length === 0)) {
        return ["(ç–‘æƒ‘) è¯¶ï¼Ÿè¿™ä»½æ–‡ä»¶å¥½åƒæ˜¯ç©ºç™½çš„å‘¢ï¼Ÿ"];
    }

    // Default persona if none provided
    const p = persona || {
        charName: 'è•¾å§†',
        userNickname: 'æ˜‚å›',
        relationship: 'çˆ±æ…•è€…',
        personality: 'æ¸©æŸ”ä½“è´´'
    };

    try {
        const parts: any[] = [];

        // 1. Add Images (Vision) if available
        if (images && images.length > 0) {
            const visualContext = images.slice(0, 15);
            visualContext.forEach(imgBase64 => {
                 const split = imgBase64.split(',');
                 if (split.length === 2) {
                     parts.push({
                         inlineData: {
                             mimeType: split[0].split(';')[0].split(':')[1] || 'image/png',
                             data: split[1]
                         }
                     });
                 }
            });
        }

        // 2. Add Text
        parts.push({ text: `FULL DOCUMENT TEXT (Truncated):\n${fullText.slice(0, 50000)}` });
        
        const prompt = `
        # ROLE: ${p.charName} (Visual Novel Character)
        - Nickname for User: ${p.userNickname}
        - Relationship: ${p.relationship}
        - Personality: ${p.personality}

        **Task:** Convert the input document (Images or Text) into a linear monologue script spoken by ${p.charName}.

        **CRITICAL RULES:**
        1.  **Output Format:** JSON Array of Strings. \`["Line 1", "Line 2", ...]\`
        2.  **Objective:** Explain the document content simply and clearly, forming a cohesive narrative.
        3.  **Constraint:** Keep each line short (under 50 chars).
        4.  **Tone & Style:** 
            - MUST reflect the [Personality] and [Relationship].
            - If [Personality] is "Tsundere (å‚²å¨‡)", use phrases like "æ‰ä¸æ˜¯ä¸ºäº†ä½ å­¦çš„å‘¢".
            - If [Personality] is "Possessive (å æœ‰æ¬²å¼º)", imply you want the user's attention.
            - Speak mostly in CHINESE.

        **Example Output:**
        [
          "(${p.charName}é è¿‘) ${p.userNickname}ï¼Œç»ˆäºè¦å¼€å§‹å­¦ä¹ äº†å—ï¼Ÿ",
          "è¿™ä»½ææ–™ä¸»è¦è®²çš„æ˜¯...",
          "ä½ çœ‹è¿™é‡Œ..."
        ]
        `;

        parts.push({ text: prompt });

        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: [
                { role: 'user', parts: parts }
            ],
            config: {
                responseMimeType: 'application/json'
            }
        });

        if (!response.text) return DEFAULT_ERROR_SCRIPT;

        const cleanedText = cleanJsonString(response.text);
        let parsedData = [];

        try {
            parsedData = JSON.parse(cleanedText);
        } catch (jsonError) {
            console.error("JSON Parse failed:", jsonError);
            return DEFAULT_ERROR_SCRIPT;
        }

        if (Array.isArray(parsedData) && parsedData.length > 0) {
            return parsedData.map(item => String(item));
        }
        
        return DEFAULT_ERROR_SCRIPT;

    } catch (error) {
        console.error("Gemini API Error:", error);
        return DEFAULT_ERROR_SCRIPT;
    }
};

// Legacy re-exports - FIXED TO PASS ARGS
export const generateRemStoryScript = (t: string, i?: string[], p?: PersonaSettings) => generatePersonaStoryScript(t, i, p);

export const runTaskHugAgent = async (userGoal: string): Promise<TaskHugResponse> => {
  try {
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: userGoal,
      config: {
        systemInstruction: `Task decomposition agent. Output JSON only.`,
        responseMimeType: 'application/json',
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            message: { type: Type.STRING },
            steps: { type: Type.ARRAY, items: { type: Type.STRING } }
          },
          required: ["message", "steps"]
        }
      }
    });
    return response.text ? JSON.parse(response.text) : { message: "Error", steps: [] };
  } catch (e) { return { message: "è¯·ç¨åå†è¯•", steps: [] }; }
};

export const runTaskHugChat = async (history: ChatMessage[], newMessage: string, currentSteps?: string[]): Promise<string> => {
  return "åŠ æ²¹ï¼";
};

export const runChatHugAgent = async (history: ChatMessage[], newMessage: string, mode: any): Promise<string> => {
  return "æˆ‘åœ¨å¬ã€‚";
};

export const performPreFlightDiagnosis = async (docContent: string): Promise<StudyMap | null> => {
  // #region agent log
  fetch('http://127.0.0.1:7242/ingest/f7788da6-7262-4420-bc72-576f23e0b7d4',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'geminiService.ts:performPreFlightDiagnosis',message:'entry',data:{},timestamp:Date.now(),hypothesisId:'H1'})}).catch(()=>{});
  // #endregion
  try {
    const contentPart = getContentPart(docContent);
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [
          { role: 'user', parts: [contentPart, { text: `æ‰§è¡Œã€é¢„é£æ£€æŸ¥ã€‘ã€‚è¯†åˆ«æ–‡æ¡£çš„ä¸»é¢˜é¢†åŸŸï¼Œå¹¶æå– 3-5 ä¸ªè¯»æ‡‚è¯¥æ–‡æ¡£å¿…é¡»å…·å¤‡çš„åŸºç¡€æ¦‚å¿µï¼ˆå‰ç½®çŸ¥è¯†ï¼‰ã€‚` }] }
      ],
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            topic: { type: Type.STRING },
            prerequisites: {
              type: Type.ARRAY,
              items: {
                type: Type.OBJECT,
                properties: {
                  id: { type: Type.STRING },
                  concept: { type: Type.STRING }
                },
                required: ["id", "concept"]
              }
            },
            initialBriefing: { type: Type.STRING }
          },
          required: ["topic", "prerequisites", "initialBriefing"]
        }
      }
    });
    if (!response.text) return null;
    const data = JSON.parse(response.text);
    const result = {
      topic: data.topic,
      initialBriefing: data.initialBriefing,
      prerequisites: data.prerequisites.map((p: any) => ({ ...p, mastered: false }))
    };
    // #region agent log
    fetch('http://127.0.0.1:7242/ingest/f7788da6-7262-4420-bc72-576f23e0b7d4',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'geminiService.ts:performPreFlightDiagnosis',message:'exit ok',data:{},timestamp:Date.now(),hypothesisId:'H1'})}).catch(()=>{});
    // #endregion
    return result;
  } catch (e) {
    // #region agent log
    fetch('http://127.0.0.1:7242/ingest/f7788da6-7262-4420-bc72-576f23e0b7d4',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({location:'geminiService.ts:performPreFlightDiagnosis',message:'catch',data:{err:String(e)},timestamp:Date.now(),hypothesisId:'H1,H3'})}).catch(()=>{});
    // #endregion
    console.error("Diagnosis Error:", e);
    return null;
  }
};

export const generateGatekeeperQuiz = async (docContent: string, topic: string): Promise<QuizData | null> => {
  try {
    const contentPart = getContentPart(docContent);
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [
        { 
            role: 'user', 
            parts: [
                contentPart, 
                { text: `Topic: ${topic}\n\nCreate a "Gatekeeper Quiz" (Single Multiple Choice Question). Language: Chinese.` }
            ] 
        }
      ],
      config: {
        responseMimeType: "application/json",
        responseSchema: {
            type: Type.OBJECT,
            properties: {
                question: { type: Type.STRING },
                options: { type: Type.ARRAY, items: { type: Type.STRING } },
                correctIndex: { type: Type.INTEGER },
                explanation: { type: Type.STRING }
            },
            required: ["question", "options", "correctIndex", "explanation"]
        }
      }
    });
    if (!response.text) return null;
    return JSON.parse(response.text) as QuizData;
  } catch (error) {
    console.error("Quiz Gen Error:", error);
    return null;
  }
};

/** æ ¹æ® PDF ç”Ÿæˆå¤šé“æµ‹éªŒé¢˜ï¼ˆå¤ä¹ ç”¨ï¼‰ã€‚existingQuestionTexts ç”¨äºã€Œç»§ç»­å‡ºé¢˜ã€æ—¶é¿å…é‡å¤ã€‚ */
export const generateQuizSet = async (
  docContent: string,
  options: { count: number; existingQuestionTexts?: string[] }
): Promise<QuizData[]> => {
  try {
    const contentPart = getContentPart(docContent);
    const noRepeat = (options.existingQuestionTexts?.length ?? 0) > 0
      ? `\n\nã€é‡è¦ã€‘ä»¥ä¸‹é¢˜ç›®å·²ç»å‡ºè¿‡ï¼Œè¯·å‹¿é‡å¤å‡ºç›¸åŒæˆ–é«˜åº¦ç›¸ä¼¼çš„é—®é¢˜ï¼š\n${options.existingQuestionTexts!.slice(-50).join('\n')}`
      : '';
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [
        {
          role: 'user',
          parts: [
            contentPart,
            {
              text: `æ ¹æ®æ–‡æ¡£å†…å®¹ç”Ÿæˆ ${options.count} é“ä¸­æ–‡é€‰æ‹©é¢˜ï¼ˆæ¯é“é¢˜ 4 ä¸ªé€‰é¡¹ï¼Œå•é€‰ï¼‰ã€‚è¦æ±‚ï¼šé¢˜ç›®è¦†ç›–æ–‡æ¡£æ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼Œé€‰é¡¹æœ‰åŒºåˆ†åº¦ã€‚${noRepeat}\n\nè¿”å› JSONï¼š{ "items": [ { "question": "...", "options": ["A", "B", "C", "D"], "correctIndex": 0, "explanation": "è§£æ..." }, ... ] }`
            }
          ]
        }
      ],
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            items: {
              type: Type.ARRAY,
              items: {
                type: Type.OBJECT,
                properties: {
                  question: { type: Type.STRING },
                  options: { type: Type.ARRAY, items: { type: Type.STRING } },
                  correctIndex: { type: Type.INTEGER },
                  explanation: { type: Type.STRING }
                },
                required: ["question", "options", "correctIndex", "explanation"]
              }
            }
          },
          required: ["items"]
        }
      }
    });
    if (!response.text) return [];
    const parsed = JSON.parse(response.text) as { items: QuizData[] };
    return Array.isArray(parsed.items) ? parsed.items : [];
  } catch (error) {
    console.error("generateQuizSet Error:", error);
    return [];
  }
};

/** æ ¹æ® PDF ä¼°ç®—å¯æ•´ç†çš„é—ªå¡æ•°é‡ã€‚ */
export const estimateFlashCardCount = async (docContent: string): Promise<number> => {
  try {
    const contentPart = getContentPart(docContent);
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [
        {
          role: 'user',
          parts: [
            contentPart,
            {
              text: 'æ ¹æ®è¿™ä»½æ–‡æ¡£çš„å†…å®¹ï¼Œä¼°ç®—å¯ä»¥æ•´ç†å‡ºå¤šå°‘å¼ ã€Œæ¦‚å¿µ-è§£é‡Šã€æˆ–ã€Œæœ¯è¯­-å®šä¹‰ã€ç±»çš„é—ªå¡ï¼ˆæ­£é¢ä¸ºæ¦‚å¿µ/é—®é¢˜ï¼ŒèƒŒé¢ä¸ºè§£é‡Š/ç­”æ¡ˆï¼‰ã€‚åªè¿”å›ä¸€ä¸ª JSON å¯¹è±¡ï¼š{ "estimatedCount": number }ï¼Œæ•°å­—ä¸ºæ•´æ•°ï¼Œä¾‹å¦‚ 15 æˆ– 30ã€‚'
            }
          ]
        }
      ],
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: { estimatedCount: { type: Type.INTEGER } },
          required: ["estimatedCount"]
        }
      }
    });
    if (!response.text) return 20;
    const parsed = JSON.parse(response.text) as { estimatedCount: number };
    const n = Number(parsed.estimatedCount);
    return Number.isFinite(n) && n > 0 ? Math.min(Math.max(n, 5), 200) : 20;
  } catch (error) {
    console.error("estimateFlashCardCount Error:", error);
    return 20;
  }
};

/** æ ¹æ® PDF ç”Ÿæˆä¸€æ‰¹é—ªå¡ã€‚existingFronts ç”¨äºã€Œå†ç”Ÿæˆæ›´å¤šã€æ—¶é¿å…é‡å¤ã€‚ */
export const generateFlashCards = async (
  docContent: string,
  options: { count: number; existingFronts?: string[] }
): Promise<Array<{ front: string; back: string }>> => {
  try {
    const contentPart = getContentPart(docContent);
    const noRepeat = (options.existingFronts?.length ?? 0) > 0
      ? `\n\nã€é‡è¦ã€‘ä»¥ä¸‹æ­£é¢å†…å®¹å·²ç»å­˜åœ¨ï¼Œè¯·å‹¿é‡å¤ï¼š\n${options.existingFronts!.slice(-80).join('\n')}`
      : '';
    const response = await ai.models.generateContent({
      model: 'gemini-3-pro-preview',
      contents: [
        {
          role: 'user',
          parts: [
            contentPart,
            {
              text: `æ ¹æ®æ–‡æ¡£æ•´ç† ${options.count} å¼ ä¸­æ–‡é—ªå¡ã€‚æ¯å¼ é—ªå¡åŒ…å« "front"ï¼ˆæ­£é¢ï¼šæ¦‚å¿µ/æœ¯è¯­/é—®é¢˜ï¼‰å’Œ "back"ï¼ˆèƒŒé¢ï¼šè§£é‡Š/å®šä¹‰/ç­”æ¡ˆï¼‰ã€‚å†…å®¹ç®€æ´æ¸…æ™°ã€‚${noRepeat}\n\nè¿”å› JSONï¼š{ "cards": [ { "front": "...", "back": "..." }, ... ] }`
            }
          ]
        }
      ],
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.OBJECT,
          properties: {
            cards: {
              type: Type.ARRAY,
              items: {
                type: Type.OBJECT,
                properties: {
                  front: { type: Type.STRING },
                  back: { type: Type.STRING }
                },
                required: ["front", "back"]
              }
            }
          },
          required: ["cards"]
        }
      }
    });
    if (!response.text) return [];
    const parsed = JSON.parse(response.text) as { cards: Array<{ front: string; back: string }> };
    return Array.isArray(parsed.cards) ? parsed.cards : [];
  } catch (error) {
    console.error("generateFlashCards Error:", error);
    return [];
  }
};

export const chatWithAdaptiveTutor = async (
    docContent: string,
    history: ChatMessage[],
    newMessage: string,
    mode: 'tutoring' | 'reading',
    docType: DocType = 'STEM'
): Promise<string> => {
    try {
        const contentPart = getContentPart(docContent);
        const contents = [];
        const adaptiveSystemPrompt = docType === 'HUMANITIES' 
            ? HUMANITIES_SYSTEM_PROMPT 
            : STEM_SYSTEM_PROMPT;

        contents.push({
            role: 'user',
            parts: [
                contentPart,
                { text: `Current Mode: ${mode === 'tutoring' ? 'Recursive Tutoring' : 'Deep Lead-Reading (Phase 1/2)'}` }
            ]
        });

        history.forEach(msg => {
            contents.push({ role: msg.role, parts: [{ text: msg.text }] });
        });

        contents.push({ role: 'user', parts: [{ text: newMessage }] });

        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: contents,
            config: { systemInstruction: adaptiveSystemPrompt }
        });

        return response.text || "Thinking...";
    } catch (error) {
        console.error("Adaptive Tutor Error:", error);
        return "é€šä¿¡ä¸­æ–­ï¼Œè¯·é‡è¯•ã€‚";
    }
};

// --- NEW: SIDE QUEST AGENT ---
export const runSideQuestAgent = async (
    history: ChatMessage[],
    newMessage: string,
    anchorText: string
): Promise<string> => {
    try {
        const SIDE_QUEST_SYSTEM_PROMPT = `
        # ğŸŒŒ Role: The Deep Dive Archivist (Side Quest Guide)
        
        The user has paused their main learning journey to trigger a "Side Quest" on the specific term: **"${anchorText}"**.
        
        **Your Goal:** Provide an Encyclopedic, Depth-First explanation of this specific concept.
        
        **Rules:**
        1. **Ignore Context Constraints**: You are NO LONGER bound by the document's scope. Use your full external knowledge base.
        2. **Structure**:
           - **Definition**: What is it? (Academic & Intuitive).
           - **Origin/History**: Where did it come from?
           - **Why it matters**: What is its core value?
           - **Fun Fact/Counter-Intuitive**: Surprise the user.
        3. **Tone**: Mysterious, profound, yet highly academic (like opening a secret tome).
        4. **Language**: Chinese (Simplified).
        
        If the user asks follow-up questions, continue to answer in this "Deep Dive" persona.
        `;

        const contents = [];
        
        // Add Chat History
        history.forEach(msg => {
            contents.push({ role: msg.role, parts: [{ text: msg.text }] });
        });

        // Add current message
        contents.push({ role: 'user', parts: [{ text: newMessage }] });

        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: contents,
            config: { systemInstruction: SIDE_QUEST_SYSTEM_PROMPT }
        });

        return response.text || "Archives inaccessible...";
    } catch (error) {
        console.error("Side Quest Error:", error);
        return "æ”¯çº¿ä»»åŠ¡è¿æ¥å¤±è´¥...";
    }
};
